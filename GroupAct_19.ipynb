{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a627fc95",
   "metadata": {},
   "source": [
    "# Inclass Activity_19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07c778",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction Techniques\n",
    "\n",
    "* Dimensionality reduction is used to reduce dimensions of our inputs from a dataset.\n",
    "\n",
    "* It won't just pick columns from the dataset like feature selection, **it will reduce the dimensions by creating new columns using datas from the dataset**.\n",
    "\n",
    "### Why it is used?\n",
    "\n",
    "* The more features we use in our model, will leads to **overfitting problem**. Dimensionality reduction helps us to reduce overfitting by keeping the more important features in the feature set and reducing the number of features that do not help to decide the output. \n",
    "                                                                                                \n",
    "### Types of dimensionality reduction techniques  \n",
    "\n",
    "   * **Linear Dimensionality Reduction**\n",
    "        * Principal component analysis (PCA)\n",
    "        * SVD \n",
    "        * Linear discriminant \n",
    "        * Non-Negative Matrix Factorization\n",
    "                \n",
    "   * **Non Linear Dimensionality Reduction**\n",
    "        * Isomap Embedding\n",
    "        * Locally Linear Embedding\n",
    "        * Multidimensional Scaling\n",
    "                                                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d60cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc4302e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df = pd.read_csv('../SupervisedML_13/diabetes.csv')\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d8f47",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "   Preprocessing is an initial step when we use Machine Learning. After loading our dataset, we have to prepare(cleaning and organizing) our data to make it suitable for Machine learning models. Some Preprocessing steps are:\n",
    "\n",
    "   * Cleaning null values,handling missing datas, removing weird symbols..\n",
    "   * Standardizing our dataset, Scaling the columns\n",
    "   * Converting categorical value columns into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f4cbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Nans in the dataset\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0273bf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7243d4f",
   "metadata": {},
   "source": [
    "* It seems like some features contains 0. There is a possibility for preganancy to be 0. But its not possible for other features(Glucose, BloodPressure, SkinThickness, Insulin, BMI). It might be, already our dataset has replaced Nans with 0s or kind of mistyping error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa79a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose : No. of 0s: 5\n",
      "BloodPressure : No. of 0s: 35\n",
      "SkinThickness : No. of 0s: 227\n",
      "Insulin : No. of 0s: 374\n",
      "DiabetesPedigreeFunction : No. of 0s: 0\n",
      "BMI : No. of 0s: 11\n"
     ]
    }
   ],
   "source": [
    "# I am writing a function to check 0s in the columns. Keeping Columns which contains 0s in a list. \n",
    "zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','DiabetesPedigreeFunction','BMI']\n",
    "\n",
    "def check_zeros(df,features):\n",
    "    for i in features:\n",
    "        print('%s : No. of 0s: %d' %(i,len(df.loc[df[i]==0,i])))\n",
    "        \n",
    "# calling zero_features function\n",
    "check_zeros(diabetes_df,zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbdfc78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose; Replaced 5 entries with value: 121.687\n",
      "BloodPressure; Replaced 35 entries with value: 72.405\n",
      "SkinThickness; Replaced 227 entries with value: 29.153\n",
      "Insulin; Replaced 374 entries with value: 155.548\n",
      "DiabetesPedigreeFunction; Replaced 0 entries with value: 0.472\n",
      "BMI; Replaced 11 entries with value: 32.457\n"
     ]
    }
   ],
   "source": [
    "# If we take mean for entire column, it will calculate including all 0s. So I am calculating only average of non zero\n",
    "# values.\n",
    "\n",
    "def impute_zeros(df, features):\n",
    "    nonzero_vals = df.loc[df[features] != 0, features]\n",
    "    avg = np.sum(nonzero_vals) / len(nonzero_vals)\n",
    "    k = len(df.loc[ df[features] == 0, features])   # num of 0-entries\n",
    "    df.loc[ df[features] == 0, features] = avg   # avg of non 0 values\n",
    "    print('%s; Replaced %d entries with value: %.3f' % (features, k, avg))\n",
    "    \n",
    "for i in zero_features:\n",
    "    impute_zeros(diabetes_df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac0de4",
   "metadata": {},
   "source": [
    "#### Logistic Regression Without using Dimensionality reduction (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3853f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 79.0 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       150\n",
      "           1       0.80      0.53      0.64        81\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.79      0.73      0.74       231\n",
      "weighted avg       0.79      0.79      0.78       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = diabetes_df.iloc[:,:-1]\n",
    "y = diabetes_df.iloc[:,-1]\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=6, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.fit_transform(X_test)\n",
    "\n",
    "#estimator = model\n",
    "LR = LogisticRegression(random_state= 6)\n",
    "\n",
    "LR = LR.fit(X_train_sc, y_train)\n",
    "print('Accuracy Score',LR.score(X_test_sc, y_test).round(2)*100,'%')\n",
    "predictions = LR.predict(X_test_sc)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c4061",
   "metadata": {},
   "source": [
    "## 1. Take one of the supervised learning models you have built recently and apply at least three dimensionality reduction techniques to it (separately). Be sure to create a short summary of each technique you use. Indicate how each changed the model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a8c4f",
   "metadata": {},
   "source": [
    "### Using PCA(Principal Component Anaysis)\n",
    "\n",
    "* PCA will give more preference to high variance features and then it will go to low variance. For instance, if n_components = 3, we are asking PCA to extract the most 3 important components. Principal Component 1(PC1) contains the most variance features, PC2 contains second most highest variance features and so on.  \n",
    "\n",
    "* We need to find the exact n_components value. Using **explained_variance_ parameter we can find the best n_components**. I am looping through to plot how many features are having high variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d0e1591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "variance = []\n",
    "for i in range(1,9):\n",
    "    pca = PCA(n_components = i)\n",
    "    pca_model = pca.fit(X_train_sc,y_train)\n",
    "    features = range(pca.n_components_)\n",
    "    exp_var = pca.explained_variance_\n",
    "    variance.append(exp_var)\n",
    "# Plot the explained variances\n",
    "plt.bar(features, pca.explained_variance_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e03a4",
   "metadata": {},
   "source": [
    "* From bar plot, I am taking features which is having variance of above 0.5 which is 7 here. Now we can apply pca method to diabetes dataset and check our performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3b91bdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report using PCA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86       150\n",
      "           1       0.83      0.53      0.65        81\n",
      "\n",
      "    accuracy                           0.80       231\n",
      "   macro avg       0.81      0.74      0.75       231\n",
      "weighted avg       0.80      0.80      0.78       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using pipeline, combining pca and logistic regression together\n",
    "\n",
    "pca = PCA(n_components = 7)\n",
    "pipeline_pca = make_pipeline(pca,LR)\n",
    "\n",
    "# Fit the pipeline to input\n",
    "pipeline_pca.fit(X_train_sc, y_train)\n",
    "\n",
    "# Now that I have trained my model, using it on test data to predict output\n",
    "y_pred_pca = pipeline_pca.predict(X_test_sc)\n",
    "\n",
    "# printing performance metrics\n",
    "print(\"classification_report using PCA\")\n",
    "print(classification_report(y_test,y_pred_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b4e00",
   "metadata": {},
   "source": [
    "* My precision got increased from 0.8 to 0.83, no changes in recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff5df6",
   "metadata": {},
   "source": [
    "### Using LDA (Linear Discriminant Analysis)\n",
    "\n",
    "* LDA handles multiple class problem very efficiently. It provides an informative low-dimensional view on the data, which is both useful for visualization and feature engineering.\n",
    "\n",
    "* But if the classes are non-linearly separable, It can not find a lower-dimensional space to project. \n",
    "\n",
    "* The number of dimensions is limited to 1 and C-1, where C is the number of classes. Our dataset is a binary classification problem, limiting the number of dimensions to 1. The “n_components” argument can be set to configure the number of desired dimensions in the output of the transform. So for this case n_components = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5eb341d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report using LDA\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       150\n",
      "           1       0.80      0.53      0.64        81\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.79      0.73      0.74       231\n",
      "weighted avg       0.79      0.79      0.78       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components = 1)\n",
    "\n",
    "pipeline_lda = make_pipeline(lda,LR)\n",
    "\n",
    "# Fit the pipeline to 'samples'\n",
    "pipeline_lda.fit(X_train_sc, y_train)\n",
    "\n",
    "y_pred_lda = pipeline_lda.predict(X_test_sc)\n",
    "\n",
    "print(\"classification_report using LDA\")\n",
    "print(classification_report(y_test,y_pred_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97590ca6",
   "metadata": {},
   "source": [
    "* After LDA, we got the same results when we used baseline. No changes from the performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93bbd3",
   "metadata": {},
   "source": [
    "### Using Isomap Embedding\n",
    "\n",
    "* Isomap Embedding is a non linear dimnensionality reduction. It preserves non linear relationships in the dataset.\n",
    "\n",
    "* Isomap techniques uses Knearest neighbors to compute shortest path and construct the neighborhood graph. It uses multi dimensional scaling to compute lower dimensional embedding.\n",
    "\n",
    "* The “n_components” argument can be set to configure the number of desired dimensions in the output of the transform. Here  I am choosing n_components = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34580292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       150\n",
      "           1       0.70      0.47      0.56        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.73      0.68      0.69       231\n",
      "weighted avg       0.74      0.74      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "iso = Isomap(n_components = 1)\n",
    "pipeline_iso = make_pipeline(iso,LR)\n",
    "\n",
    "# Fit the pipeline to 'samples'\n",
    "pipeline_iso.fit(X_train_sc, y_train)\n",
    "\n",
    "y_pred_iso = pipeline_iso.predict(X_test_sc)\n",
    "print(classification_report(y_test,y_pred_iso))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d22b53",
   "metadata": {},
   "source": [
    "* Both of my precision and recall reduced using Isomap when we compared it to baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea4307",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "\n",
    "|       Method             |       Precision      |     Recall         |\n",
    "|:------------------------:|:--------------------:|:------------------:|\n",
    "|    Baseline              |         0.80         |     0.53           |                    \n",
    "|    PCA (Linear)          |         0.83         |     0.53           |              \n",
    "|    LDA (Linear)          |         0.80         |     0.53           |\n",
    "| Isomap(Non Linear)       |         0.70         |     0.47           |   \n",
    "\n",
    "* Out of these 3 methods, PCA delivered improved precision and same recall than baseline.  It may be challenging to choose the right dimensionality reduction technique for our data. However, if we are looking for a non-linear approach, then Locally Linear Embedding (LLE) and Isometric Mapping (Isomap) would be good ones to explore. If we are looking for linear dimensionality, then PCA, SVD, Linear discriminant are good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded20fe8",
   "metadata": {},
   "source": [
    "## 2. Write a function that will indicate if an inputted IPv4 address is accurate or not. IP addresses are valid if they have 4 values between 0 and 255 (inclusive), punctuated by periods.\n",
    "\n",
    "Input 1:\n",
    "2.33.245.5\n",
    "Output 1:\n",
    "True\n",
    "\n",
    "Input 2:\n",
    "12.345.67.89\n",
    "Output 2:\n",
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c630ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def address(ip):\n",
    "    print(\"Input: \",ip)\n",
    "    if re.match(r'^((\\d{1,2}|1\\d{2}|2[0-4]\\d|25[0-5])\\.){3}(\\d{1,2}|1\\d{2}|2[0-4]\\d|25[0-5])$', ip):  \n",
    "        print (\"Output: True\")\n",
    "    else:\n",
    "        print (\"Output: False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6ca341",
   "metadata": {},
   "source": [
    "#### Combinations we might have: \n",
    "\n",
    "* I am using regex patterns to match our given IP address meets the required specification or not.\n",
    "\n",
    "\\d - any number from 0 to 9 \n",
    "\n",
    "\\d{1,2} - after \\d, we might have 1 or 2 \n",
    "\n",
    "| - or operator\n",
    "\n",
    "1\\d{2} - first integer is 1, 2nd digit is any integer from 0 to 9 and third integer is 2\n",
    "\n",
    "2[0-4]\\d - after 2 we might have a any digit from 0 to 4 and then any digit from 0 to 9(total 3 digits)\n",
    "\n",
    "25[0-5] - we know that values between 0 and 255(inclusive). So first 2 digits are 2 and 5, and last digit any digit from 0 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "98eb7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  2.33.245.5\n",
      "Output: True\n"
     ]
    }
   ],
   "source": [
    "address(\"2.33.245.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "689aa996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  12.345.67.89\n",
      "Output: False\n"
     ]
    }
   ],
   "source": [
    "address(\"12.345.67.89\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
